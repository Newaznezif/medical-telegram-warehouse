

# Telegram Medical Data Warehouse â€“ Task 1 & Task 2

**Ethiopian Medical & Cosmetics Intelligence Platform**

---

## ğŸ“Œ Project Overview

This project collects, processes, models, and analyzes data from **public Ethiopian medical and cosmetic Telegram channels**.
It is built as an **end-to-end data engineering pipeline**, moving from raw data ingestion to a fully modeled PostgreSQL data warehouse ready for analytics and machine learning.

---

## ğŸ¯ Objectives

### Task 1 â€“ Data Scraping & Exploration

* Scrape messages and media from public Telegram channels
* Store raw data in structured JSON format
* Download and organize media (images)
* Perform Exploratory Data Analysis (EDA)
* Generate insights to guide data modeling

### Task 2 â€“ Data Modeling & Warehousing

* Load raw Telegram data into PostgreSQL
* Build a **star-schema data warehouse** using dbt
* Create staging, dimension, and fact models
* Apply data quality tests
* Enable analytics-ready datasets

---

## ğŸ—‚ï¸ Repository Structure

```
medical-telegram-warehouse/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ images/                      # Downloaded media by channel
â”‚   â”‚   â””â”€â”€ telegram_messages/           # Raw JSON message files (by date)
â”‚   â”œâ”€â”€ processed/                       # Cleaned/derived datasets
â”‚   â””â”€â”€ staging/                         # Intermediate files (optional)
â”‚
â”œâ”€â”€ medical_warehouse/                   # dbt project
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â””â”€â”€ stg_telegram_messages.sql
â”‚   â”‚   â””â”€â”€ marts/
â”‚   â”‚       â”œâ”€â”€ dim_channels.sql
â”‚   â”‚       â”œâ”€â”€ dim_dates.sql
â”‚   â”‚       â””â”€â”€ fct_messages.sql
â”‚   â””â”€â”€ tests/
â”‚       â””â”€â”€ *.sql
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb                # Task 1 EDA
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/
â”‚   â”‚   â””â”€â”€ config.py                    # Centralized config
â”‚   â””â”€â”€ scraper.py                      # Telegram scraping logic
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ load_json_to_postgres.py         # Load raw JSON into PostgreSQL
â”‚
â”œâ”€â”€ logs/                                # Scraper and pipeline logs
â”œâ”€â”€ tests/                               # Unit tests
â”œâ”€â”€ docker-compose.yml                   # PostgreSQL container
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/yourusername/medical-telegram-warehouse.git
cd medical-telegram-warehouse
```

---

### 2ï¸âƒ£ Create & Activate Virtual Environment

```bash
python -m venv venv
.\venv\Scripts\activate     # Windows
# or
source venv/bin/activate   # Linux/macOS
```

---

### 3ï¸âƒ£ Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

---

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file in the project root:

```env
TELEGRAM_API_ID=your_api_id
TELEGRAM_API_HASH=your_api_hash
TELEGRAM_PHONE=your_phone_number

TELEGRAM_CHANNELS=@chemed123,@lobelia4cosmetics,@tikvahpharma

DB_HOST=localhost
DB_PORT=5432
DB_NAME=medical_warehouse
DB_USER=admin
DB_PASSWORD=admin123

RAW_DATA_PATH=./data/raw
PROCESSED_DATA_PATH=./data/processed
LOG_PATH=./logs
```

---

## ğŸš€ Task 1 â€“ Data Scraping & Exploration

### 1ï¸âƒ£ Run the Telegram Scraper

```bash
python -m src.scraper
```

**What this does:**

* Scrapes messages from configured Telegram channels
* Saves messages as JSON files by date
* Downloads images/media per channel
* Logs progress and errors to `logs/`

---

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)

```bash
jupyter notebook notebooks/exploration.ipynb
```

The notebook includes:

* Dataset overview and schema inspection
* Channel-level activity analysis
* Engagement metrics (views, forwards)
* Text length and content analysis
* Temporal trends (daily, hourly)
* Data quality checks
* Business insights to guide modeling

---

### âœ… Task 1 Summary

* Scraped **3 Ethiopian medical/cosmetics channels**
* Stored raw data in structured JSON format
* Downloaded associated images
* Generated EDA insights
* Prepared data for warehousing

---

## ğŸ—ï¸ Task 2 â€“ Data Modeling & Data Warehouse

### 1ï¸âƒ£ Start PostgreSQL with Docker

```bash
docker-compose up -d
```

* PostgreSQL runs on **port 5432**
* Database: `medical_warehouse`

---

### 2ï¸âƒ£ Load Raw JSON Data into PostgreSQL

```bash
python scripts/load_json_to_postgres.py
```

**Result:**

* `raw_telegram.telegram_messages` populated
* **1071 messages loaded**

---

### 3ï¸âƒ£ Run dbt Models

```bash
cd medical_warehouse
dbt run
```

---

### 4ï¸âƒ£ Validate Data Quality

```bash
dbt test
```

---

## ğŸ“Š Data Warehouse Architecture (Star Schema)

```
raw_telegram.telegram_messages        (1071 rows)
        â†“
dbt_staging.stg_telegram_messages    (cleaned view)
        â†“
dbt_marts.dim_channels               (3 channels)
dbt_marts.dim_dates                  (82 dates)
dbt_marts.fct_messages               (1071 messages)
```

---

## ğŸ§ª Data Quality Tests

* No future-dated messages
* Positive engagement metrics
* Referential integrity between facts and dimensions

---

## âœ… Task 2 Summary

* PostgreSQL data warehouse deployed
* dbt project fully configured
* Staging, dimension, and fact models built
* 1071 Telegram messages modeled
* Star-schema ready for analytics and ML

---

## ğŸ”œ Next Steps â€“ Task 3 (YOLO Image Enrichment)

* Apply YOLOv8 to Telegram images
* Detect medical and cosmetic products
* Enrich warehouse with image intelligence
* Enable visual analytics & AI-driven insights

---

## ğŸ Final Notes

This project follows **industry-standard data engineering practices**:

* Raw â†’ Staging â†’ Marts
* Version-controlled dbt models
* Reproducible pipelines
* Analytics-ready schemas

You are now set up for **advanced analytics, dashboards, and AI enrichment** ğŸš€

---

